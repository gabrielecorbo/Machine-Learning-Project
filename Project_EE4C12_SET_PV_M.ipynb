{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1285e679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_curve, plot_roc_curve, confusion_matrix, plot_confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e00526",
   "metadata": {},
   "source": [
    "# Data Pre-processing and Feature Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f24e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irradiance</th>\n",
       "      <th>Ambient_Temperature</th>\n",
       "      <th>Sun_Azimuth</th>\n",
       "      <th>Sun_Elevation</th>\n",
       "      <th>System_Power</th>\n",
       "      <th>System_Age</th>\n",
       "      <th>System_Status</th>\n",
       "      <th>Fault_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-71.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.073277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1290.467722</td>\n",
       "      <td>3.731482</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-49.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>366.571466</td>\n",
       "      <td>0.236534</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-46.3</td>\n",
       "      <td>45.3</td>\n",
       "      <td>2261.488687</td>\n",
       "      <td>1.720781</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-107.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2616.082381</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>62</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-17.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>118.293683</td>\n",
       "      <td>13.476348</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>114</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>33.2</td>\n",
       "      <td>253.335320</td>\n",
       "      <td>4.542954</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>144</td>\n",
       "      <td>6.1</td>\n",
       "      <td>41.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>526.328072</td>\n",
       "      <td>14.553955</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>486</td>\n",
       "      <td>9.6</td>\n",
       "      <td>56.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1707.208551</td>\n",
       "      <td>6.610661</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-29.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>201.616715</td>\n",
       "      <td>22.294729</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Irradiance  Ambient_Temperature  Sun_Azimuth  Sun_Elevation  \\\n",
       "0             713                  3.8        -71.3           19.8   \n",
       "1             152                  2.7        -28.2           11.7   \n",
       "2              75                  4.5        -49.6           23.1   \n",
       "3             379                 17.7        -46.3           45.3   \n",
       "4             453                 14.2       -107.2           15.9   \n",
       "...           ...                  ...          ...            ...   \n",
       "11995          62                 10.2        -17.2           13.3   \n",
       "11996         114                 14.8        -17.4           33.2   \n",
       "11997         144                  6.1         41.2            6.4   \n",
       "11998         486                  9.6         56.1           14.8   \n",
       "11999         103                 13.0        -29.1           18.9   \n",
       "\n",
       "       System_Power  System_Age  System_Status  Fault_Type  \n",
       "0       5000.000000    0.073277              0           0  \n",
       "1       1290.467722    3.731482              0           0  \n",
       "2        366.571466    0.236534              0           0  \n",
       "3       2261.488687    1.720781              0           0  \n",
       "4       2616.082381    0.674352              0           0  \n",
       "...             ...         ...            ...         ...  \n",
       "11995    118.293683   13.476348              1           3  \n",
       "11996    253.335320    4.542954              1           3  \n",
       "11997    526.328072   14.553955              1           3  \n",
       "11998   1707.208551    6.610661              1           3  \n",
       "11999    201.616715   22.294729              1           3  \n",
       "\n",
       "[12000 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "data_orig = pd.read_csv('Project_Data_EE4C12_SET_PV.csv')\n",
    "data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456882b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Irradiance</th>\n",
       "      <th>Ambient_Temperature</th>\n",
       "      <th>Sun_Azimuth</th>\n",
       "      <th>Sun_Elevation</th>\n",
       "      <th>System_Power</th>\n",
       "      <th>System_Age</th>\n",
       "      <th>System_Status</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Short_Circuit</th>\n",
       "      <th>Broken_Cells</th>\n",
       "      <th>Broken_Strings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>713</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-71.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.073277</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-28.2</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1290.467722</td>\n",
       "      <td>3.731482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>4.5</td>\n",
       "      <td>-49.6</td>\n",
       "      <td>23.1</td>\n",
       "      <td>366.571466</td>\n",
       "      <td>0.236534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>379</td>\n",
       "      <td>17.7</td>\n",
       "      <td>-46.3</td>\n",
       "      <td>45.3</td>\n",
       "      <td>2261.488687</td>\n",
       "      <td>1.720781</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>453</td>\n",
       "      <td>14.2</td>\n",
       "      <td>-107.2</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2616.082381</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>62</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-17.2</td>\n",
       "      <td>13.3</td>\n",
       "      <td>118.293683</td>\n",
       "      <td>13.476348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>114</td>\n",
       "      <td>14.8</td>\n",
       "      <td>-17.4</td>\n",
       "      <td>33.2</td>\n",
       "      <td>253.335320</td>\n",
       "      <td>4.542954</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>144</td>\n",
       "      <td>6.1</td>\n",
       "      <td>41.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>526.328072</td>\n",
       "      <td>14.553955</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>486</td>\n",
       "      <td>9.6</td>\n",
       "      <td>56.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>1707.208551</td>\n",
       "      <td>6.610661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>103</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-29.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>201.616715</td>\n",
       "      <td>22.294729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Irradiance  Ambient_Temperature  Sun_Azimuth  Sun_Elevation  \\\n",
       "0             713                  3.8        -71.3           19.8   \n",
       "1             152                  2.7        -28.2           11.7   \n",
       "2              75                  4.5        -49.6           23.1   \n",
       "3             379                 17.7        -46.3           45.3   \n",
       "4             453                 14.2       -107.2           15.9   \n",
       "...           ...                  ...          ...            ...   \n",
       "11995          62                 10.2        -17.2           13.3   \n",
       "11996         114                 14.8        -17.4           33.2   \n",
       "11997         144                  6.1         41.2            6.4   \n",
       "11998         486                  9.6         56.1           14.8   \n",
       "11999         103                 13.0        -29.1           18.9   \n",
       "\n",
       "       System_Power  System_Age  System_Status  Healthy  Short_Circuit  \\\n",
       "0       5000.000000    0.073277              0        1              0   \n",
       "1       1290.467722    3.731482              0        1              0   \n",
       "2        366.571466    0.236534              0        1              0   \n",
       "3       2261.488687    1.720781              0        1              0   \n",
       "4       2616.082381    0.674352              0        1              0   \n",
       "...             ...         ...            ...      ...            ...   \n",
       "11995    118.293683   13.476348              1        0              0   \n",
       "11996    253.335320    4.542954              1        0              0   \n",
       "11997    526.328072   14.553955              1        0              0   \n",
       "11998   1707.208551    6.610661              1        0              0   \n",
       "11999    201.616715   22.294729              1        0              0   \n",
       "\n",
       "       Broken_Cells  Broken_Strings  \n",
       "0                 0               0  \n",
       "1                 0               0  \n",
       "2                 0               0  \n",
       "3                 0               0  \n",
       "4                 0               0  \n",
       "...             ...             ...  \n",
       "11995             0               1  \n",
       "11996             0               1  \n",
       "11997             0               1  \n",
       "11998             0               1  \n",
       "11999             0               1  \n",
       "\n",
       "[12000 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset transformation using one-hot encoding for multi-class classification\n",
    "\n",
    "data = data_orig.drop('Fault_Type', axis=1) # remove the ordinary encoding column\n",
    "data['Healthy'] = np.where(data_orig['Fault_Type'] == 0, 1, 0)\n",
    "data['Short_Circuit'] = np.where(data_orig['Fault_Type'] == 1, 1, 0)\n",
    "data['Broken_Cells'] = np.where(data_orig['Fault_Type'] == 2, 1, 0)\n",
    "data['Broken_Strings'] = np.where(data_orig['Fault_Type'] == 3, 1, 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5302be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimention:  (12000, 11)\n",
      "Noo missing values\n"
     ]
    }
   ],
   "source": [
    "print('Dataset dimention: ', data.shape)\n",
    "if data.isnull().values.any():\n",
    "    print('Some values are missing')\n",
    "else:\n",
    "    print('Noo missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58aa61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mc_1d=data_orig.iloc[:,7]\n",
    "y_mc_train1d,y_mc_test1d = train_test_split(y_mc_1d, test_size=0.15, random_state=4720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82c0b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-testing sets split: from now on the testing set must not be part of any operation, in order to prevent data leak\n",
    "\n",
    "training_set, testing_set = train_test_split(data, test_size=0.15, random_state=4720)\n",
    "\n",
    "X_training = training_set[['Irradiance', 'Ambient_Temperature', 'Sun_Azimuth', 'Sun_Elevation', \n",
    "                              'System_Power', 'System_Age']]\n",
    "y_2c_training = training_set['System_Status']\n",
    "y_mc_training = training_set[['Healthy', 'Short_Circuit', 'Broken_Cells', 'Broken_Strings']]\n",
    "\n",
    "X_test = testing_set[['Irradiance', 'Ambient_Temperature', 'Sun_Azimuth', 'Sun_Elevation', \n",
    "                              'System_Power', 'System_Age']]\n",
    "y_2c_test = testing_set['System_Status']\n",
    "y_mc_test = testing_set[['Healthy', 'Short_Circuit', 'Broken_Cells', 'Broken_Strings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a645ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "195bfc2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3edf8194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAckAAAFgCAYAAADQLIJXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3HElEQVR4nO3deZwcdZ3/8debQAQJhxyLHIEghjsQIFyKEgERFEExCFGRIGvUVfDcXRQPxAv1tx6gguGKILsgIhAVA4gEIggkkEgICMSAEkC5bwhm5vP7o75DKsP0dPd091TVzPvpox7TdXTVp8cwn/7eigjMzMzslVYqOgAzM7OycpI0MzOrwUnSzMysBidJMzOzGpwkzczManCSNDMzq8FJ0szMKkHS2ZIelnR7jfOSdIqkRZJuk7Rzq890kjQzs6qYDhzQz/kDgbFpmwqc1uoDnSTNzKwSIuI64PF+LjkEODcyNwJrS9qwlWeu3MqbrXr+9ejiyk2x9PhhRxcdQlOOXLRa0SE07TsrjSw6hKZt/b+HFx1CUw4+4ryiQ2jalffPVKv3aOZvzsj1t/gIWQmwx7SImNbE4zYG7s/tL0nHHmriHitwkjQzs87p7mr40pQQm0mKHeckaWZmnRPdg/m0B4DRuf1N0rEBc5ukmZl1Tnd341vrZgAfTL1c9wCeiogBV7WCS5JmZtZB0caSpKT/AyYC60laAnwFWCV7TpwOXA68HVgEPA+03KHBSdLMzDqnPSVEACJicp3zAXy8bQ/ESdLMzDqp619FR9ASJ0kzM+ucwe2403ZOkmZm1jltrG4tgpOkmZl1TDs77hTBSdLMzDrHJUkzM7MaXJI0MzOrwb1bzczMaqh4daunpetF0rNtvt8UST9Krz8q6YPtvL+ZWalFd+NbCbkk2QBJK0fEslr7jUrTJpmZDR8uSQ5NkiZKmi1pBnBH7/10zaWSbpG0UNLU3HuPlnS3pJuBN+aOnyjpc+n1hyXNkfRnSRdLenU6Pl3SKZJukLRY0qTc+/9b0oL0npPTsS0kzUxxzJa09aD8gszMGhDR1fBWRi5J9m9nYPuIuFfSxPx+Ov+hiHhc0mrAHEkXAyOBrwK7AE8B1wDz+rj3ryLiDABJXweOAU5N5zYE9gK2JpvV/peSDiRbdXv3iHhe0jrp2mnARyPiHkm7Az8B9mnbb8DMrBVdTVe6lYqTZP9uziXEvvaPk/Tu9Ho0MBZ4LTArIh4BkHQhsGUf994+Jce1gVHAFblzl0Y2AvcOSRukY/sB50TE8wApOY8C3gBcJL28gPirBvZRzcw6oKRtjY1ydWv/nqu1n0qW+wF7RsSOZKXFVZu493TgExExjqzkmX/v0txrUdtKwJMRMT63bdP7IklTJc2VNPfMc/+viRDNzFrU3dX4VkJOkgO3FvBEqvrcGtgjHb8J2FvSupJWAQ6r8f41gIfSNe9v4HlXAUfn2i7XiYingXslHZaOSdKOvd8YEdMiYkJETPj3D/a70oyZWXtVvHerk+TAzQRWlnQncDJwI0BaBftE4E/A9cCdNd7/JbKEej3wl3oPi4iZZO2TcyXNBz6XTr0fOEbSn4GFZO2WZmbl0N3d+FZCbpPsJSJGpZ+zgFm54733lwIH1rjHOcA5fRw/Mff6NOC0Pq6Z0lc86fXJZAk5f/5e4ICaH8jMrEglLSE2yknSzMw6Z5l7t5qZmfWprOMfG+UkaWZmnVPStsZGOUmamVnnuE3SzMysBpckzczManBJ0szMrAbP3WpmZlaDq1vNzMxqcJI0MzOroeJtkp671czMOqeNc7dKOkDSXZIWSTq+j/ObSrpG0jxJt0l6e6vhuyRpZmad06aOO5JGAD8G3gosIVvofkZE3JG77IvALyLiNEnbApcDY1p5rkuSZmbWOe1bKms3YFFELI6Il4ALeOWqRwGsmV6vBTzYavguSZqZWec00XFH0lRgau7QtIiYll5vDNyfO7cE2L3XLU4ErpR0LLA6sF+z4fbmJDnMPH7Y0UWH0LR1LnrFqmOlduhOXy46hKZtPvGhokNo2o2HXlp0CM0ZWXQABWkiSaaEOK3uhbVNBqZHxP9I2hM4T9L2EQPvPeQkaWZmnRPRrjs9AIzO7W+SjuUdQ1pfNyL+JGlVYD3g4YE+1G2SZmbWOe3r3ToHGCtpc0kjgSOAGb2u+TuwL4CkbYBVgUdaCd8lSTMz65w29W6NiGWSPgFcAYwAzo6IhZJOAuZGxAzgs8AZkj5N1olnSkRrRVknSTMz65w2zrgTEZeTDevIH/ty7vUdwBvb9kCcJM3MrJPa1yZZCCdJMzPrHM/damZmVoOTpJmZWQ0Vn+DcSdLMzDomlnUVHUJLnCTNzKxzXJI0MzOrodu9W83MzPrmjjtmZmY1VDxJNjR3q6R3SQpJWzdzc0nTJU3q4/gESac0c69e7/9CP+fWlTQ/bf+Q9EBuv3Tz8EuaKOkNRcdhZtYRXV2NbyXU6ATnk4E/pp8ti4i5EXFcC7eomSQj4rGIGB8R44HTge/37KeFOgedpP5K7BOBppJknfuZmZVHdzS+lVDdJClpFLAX2RIkR6RjEyVdK+kySYslnSzp/ZJulrRA0ha5W+wnaa6kuyUdlHv/b9Lr1SWdnd47T9Ih6fgUSb+SNFPSPZK+k46fDKyWSobnN/pBJe2SYr5F0hWSNkzHZ0n6forxTkm7pufeI+nr6Zoxkv4i6fx0zS8lvbqB+/5A0lzgk5LeKemm9Bl/L2kDSWOAjwKfTp/nTb1L35Kezf3OZkuaAdwhaYSk70qaI+k2SR9p9HdhZjZoorvxrYQaKUkeAsyMiLuBxyTtko7vSPYHfhvgSGDLiNgNOBM4Nvf+McBuwDuA09P6XnknAH9I730L8F1Jq6dz44HDgXHA4ZJGR8TxwAupZPj+Rj6kpFWAU4FJEbELcDbwjdwlL0XEBLKS52XAx4HtgSmS1k3XbAX8JCK2AZ4G/qOB+46MiAkR8T9kJfE9ImIn4ALgvyLiPlYs7c6u81F2Bj4ZEVuSfWl5KiJ2BXYFPixp80Z+H2Zmg6biJclGqu0mAz9Mry9I+78B5kTEQwCS/gpcma5ZQJbsevwirQp9j6TFQO92zf2BgyV9Lu2vCmyaXl8dEU+lZ9wBbAbc3+Bny9uKLOldJQmyZVbyS7H3rEm2AFiY+1yLyRb5fBK4PyKuT9f9HDgOmFnnvhfmXm8CXJhKmiOBewfwOW6OiJ737Q/skCt1rgWM7eu+kqYCUwG+u+VYjtxowwE82syseVHxjjv9JklJ6wD7AOMkBVkSCOC3wNLcpd25/e5e9+399aD3voD3RMRdvZ69e69ndNWLtx8iS3571jifj7335+p5Zl+fo959n8u9PhX4XkTMkDQROLHGe5aRSviSViJLqH3dT8CxEXFFjfssDzRiGjAN4J9v2bucX9fMbGgqaQmxUfWqWycB50XEZhExJiJGk5VU3tTEMw6TtFJqp3wdcFev81cAxyoVxSTt1MA9/5WqOht1F7C+pD3TM1aRtF0T7wfYtOf9wPvIqk+bue9awAPp9VG5488Aa+T27wN6qrQPBmp9ziuAj/X8HiRtmaumNjMrhyHeu3UycEmvYxfTXC/XvwM3A78DPhoRL/Y6/zWyRHCbpIVpv55p6fqGOu6kXq2TgG9L+jMwnyZ7lJIlxI9LuhN4DXBak/c9EbhI0i3Ao7njvwbe3dNxBzgD2Dvdb09WLD3mnQncAdwq6Xbgp3jcq5mVTXd341sJKSq+IOZgSL1QfxMR2xcdS6uqWN26zkXnFB1CU87a6cv1LyqZyfs8VP+ikpk3c52iQ2jKN0c+U3QITbvy/plq9R7PffmIhv/mrH7SBS0/r91c8jAzs84p6dCORlU6SabhGVf3cWrfiHisXc9JQzUqX4o0Mxt0Fe+4U+kkmRLh+KLjMDOzvnk9STMzs1pckjQzM6vBbZJmZmY1uCRpZmbWt3CSNDMzq6HiSbLR9STNzMyat6yr8a0OSQdIukvSIknH17jmvZLukLRQ0v+2Gr5LkmZm1jltKklKGgH8GHgrsASYI2lGRNyRu2Ys8HngjRHxhKR/a/W5LkmamVnHRETDWx27AYsiYnGaN/sCsvWO8z4M/DginkjPfrjV+J0kzcysc5pYdFnSVElzc9vU3J02ZsX1hJekY3lbAltKul7SjZIOaDV8V7eamVnnNFHdml/7doBWJlt8fiLZQvfXSRoXEU+2ckMbRo5ctFrRITTt0IqtqnHMvJOKDqFpB+70saJDaNqIkc8WHYI1oI1DQB4ARuf2N2H5Gr09lgA3RcS/gHsl3U2WNOcM9KGubjUzs85ZFo1v/ZsDjJW0uaSRwBHAjF7XXEpWikTSemTVr4tbCd8lSTMz65h2lSQjYpmkTwBXACOAsyNioaSTgLkRMSOd21/SHUAX8J+trgjlJGlmZp3TxskEIuJy4PJex76cex3AZ9LWFk6SZmbWOdWe39xJ0szMOsdzt5qZmdUQ9TvklJqTpJmZdY6rW83MzPpW8TWXnSTNzKyDnCTNzMz65pKkmZlZLU6SZmZmfeteVnQErXGSNDOzjql6deuQneBc0gmSFkq6TdJ8Sbu3+f7vkhSStm7g2hva9Mwxkt6X258i6UftuLeZWUeEGt9KaEgmSUl7AgcBO0fEDsB+rLhYZztMBv6YfvYrIt7QpmeOAd5X7yIzs7KI7sa3MhqSSRLYEHg0IpYCRMSjEfGgpPvS8ilImiBpVnp9oqSzJc2StFjScf3dXNIoYC/gGLLlWnqOn5RKrfMlPSDpnHT82fRzoqRrJV2WnnOypPdLulnSAklbpOumS5qUu2/PwnknA29K9/90OraRpJmS7pH0nVZ/cWZm7RTdangro6GaJK8ERku6W9JPJO3dwHu2Bt4G7AZ8RdIq/Vx7CDAzIu4GHpO0C2Sz0UfEeLL1zB4H+qoK3RH4KLANcCSwZUTsBpwJHFsnxuOB2RExPiK+n46NBw4HxgGHSxpd681mZoPNJckSiohngV2AqcAjwIWSptR5228jYmlEPAo8DGzQz7WTgQvS6wvIVblKEvBz4HsRcUsf750TEQ+lUu5fyRI6wAKy6tRmXR0RT0XEi8AdwGa9L5A0VdJcSXOXPNvuWmczs9q6u9TwVkZDtndrRHQBs4BZkhYARwHLWP7FYNVeb1mae91Fjd+NpHWAfYBxkoJs8c+Q9J9pLbMTgSURcU6N0PLP6c7td+ee+XKcklYCRtb8oA3EHRHTgGkA+48+oNqzDZtZpZS1GrVRQ7IkKWkrSWNzh8YDfwPuIythArxngLefBJwXEZtFxJiIGA3cS9ZW+E6yTkL9tmk2IB/nwUBP1e8zwBot3tvMbNBENL6V0VAtSY4CTpW0NlmpbBFZ1es2wFmSvkZWyhyIycC3ex27OB3fGtgYuDmrdWVGftXsJpwBXCbpz8BM4Ll0/DagKx2fDjwxgHubmQ2aqpckFWVN39YRVaxuPZT1ig6hKcfMO6noEJp24E4fKzqEpo2oWEVYULn/9Ljy/pktZ7j7xr+14Q8+Zv5VpcuoQ7UkaWZmJVDWDjmNcpKsQdK6wNV9nNo3Ih4b7HjMzKooSjqTTqOcJGtIiXB80XGYmVVZWcc/NspJ0szMOqbbJUkzM7O+ubrVzMyshqoPAXGSNDOzjql679ZqDTQyM7NK6Q41vNUj6QBJd0laJOn4fq57T1rvd0Kr8bskaWZmHdOuNklJI4AfA28FlgBzJM2IiDt6XbcG8EngpnY81yVJMzPrmDbO3bobsCgiFkfES2QrMB3Sx3VfI5s69MV2xO8kaWZmHdNMdWt+Wb+0Tc3damMgv9bfknTsZZJ2BkZHxG/bFb+rW83MrGOaqW7NL+vXrLSs4PeAKQN5fy1OkmZm1jFd7RsC8gAwOre/STrWYw1ge7I1hAFeC8yQdHBEzB3oQ50kh5nvrNTf+s3ltPnEh4oOoSlVXFHjd/NOKzqEpl24w0BWoSvO+SOG55TPbZxMYA4wVtLmZMnxCOB9y58TT8HyJYMkzQI+10qCBCdJMzProHZNSxcRyyR9ArgCGAGcHRELJZ0EzI2IGW15UC9OkmZm1jHtXEUzIi4HLu91rM8qhYiY2I5nOkmamVnHeIJzMzOzGrqcJM3MzPoWOEmamZn1qbudjZIFcJI0M7OO6XZJ0szMrG+ubjUzM6uhu+gAWuQkaWZmHdPlkqSZmVnfXJI0MzOrwW2SZmZmNbRvEZBiVH7RZUknSFoo6TZJ8yXt3sZ7d6V79mzHp+OzJE1o13PSPT8l6dW5/cslrd3OZ5iZDbZu1PBWRpUuSUraEzgI2DkilkpaD2jnWlAvRMT4Nt6vP58Cfg48DxARbx+k55qZdUxX0QG0qOolyQ2BRyNiKUBEPBoRD0q6LyVMJE1I64oh6URJZ6eS4GJJx7UagKT9Jf1J0q2SLpI0StIBki7KXTNR0m/S69MkzU2l36+mY8cBGwHXSLomHct/hs9Iuj1tn0rHxki6U9IZ6V5XSlqt1c9jZtZO3VLDWxlVPUleCYyWdLekn0jau4H3bA28DdgN+IqkVfq5drVe1a2H50+mJPZFYL+I2BmYC3wG+D2wu6TV06WHAxek1ydExARgB2BvSTtExCnAg8BbIuItvZ6xC3A0sDuwB/BhSTul02OBH0fEdsCTwHsa+PxmZoMmmtjKqNJJMiKeBXYBpgKPABdKmlLnbb+NiKUR8SjwMLBBP9e+EBHjc9uFvc7vAWwLXC9pPnAUsFlELANmAu+UtDLwDuCy9J73SroVmAdsl97fn72ASyLiufR5fwW8KZ27NyLmp9e3AGP6uoGkqan0OvfiZ/9W53FmZu3T3cRWRpVukwSIiC5gFjBL0gKyRLWM5V8AVu31lqW511209jsQcFVETO7j3AXAJ4DHyVbNfkbS5sDngF0j4glJ0/uIrxm9P0uf1a0RMQ2YBjB/s4PL+oXNzIYg924tkKStJI3NHRoP/A24j6yECZ2tgrwReKOk16d4Vpe0ZTp3LbAz8GGWV7WuCTwHPCVpA+DA3L2eAdbo4xmzgXdJenWqvn13OmZmVnru3VqsUcCpaajEMmARWdXrNsBZkr5GVsocqNVSNWqPmRFxfM9ORDySqnf/T9Kr0uEvAndHRFfqrDOFrHRLRPxZ0jzgL8D9wPW5e08DZkp6MN8uGRG3phLnzenQmRExT9KYFj6Xmdmg6Cpn7mtYpZNkRNwCvKGPU7OBLXsfjIgTe+1vX+f+I2ocn5h7/Qdg1xrXfYKsyjV/bEqNa08FTs3tj8m9/h7wvV7X3wdsn9v/fzU+hplZYcra1tioSidJMzMrt6p3ghj2SVLSusDVfZzaNyIeG+x4zMyGkqp33Bn2STIlwvFFx2FmNhS5utXMzKwGJ0kzM7Ma3LvVzMyshqqXJCs9mYCZmZVbO+duTYtH3CVpUc/Shb3Of0bSHWnpxKslbdZq/E6SZmbWMd1qfOuPpBHAj8lmKtsWmCyp99zX84AJEbED8EvgO63G7yRpZmYd08YJzncDFkXE4oh4iWy6z0PyF0TENRHxfNq9Edik1fjdJmlmZh3TxkWXNyabzrPHErIlBGs5Bvhdqw91kjQzs45pZjIBSVPJ5t/uMS2tYtQUSR8AJgCNrDHcLydJMzPrmGZ6t+aX9evDA8Do3P4m6dgKJO0HnADsHRFLe59vltskzcysY9rYu3UOMFbS5pJGAkcAM/IXSNoJ+ClwcEQ83I74XZIcZrb+38OLDqFpNx56adEhNGXEyGeLDqFpF+7w5aJDaNrht51UdAhNmbLRm4oOoRDdbZriPCKWSfoEcAUwAjg7IhZKOolsYfsZwHfJllC8SBLA3yPi4Fae6yRpZmYd087JBCLicuDyXse+nHu9XxsfBzhJmplZB7Wxd2shnCTNzKxjvFSWmZlZDe1qkyyKk6SZmXVMtVOkk6SZmXVQ1VcBcZI0M7OOcXWrmZlZDe7damZmVoNLkmZmZjVUO0U6SZqZWQe5446ZmVkNUfGypJOkmZl1zDInSTMzs75VO0VWfD1JSSdIWijpNknzJe3e5PunSNqoU/GlZ3Sl2G6XdJGkV3fyeWZmZdJNNLyVUWWTpKQ9gYOAnSNiB2A/4P4mbzMF6GiSBF6IiPERsT3wEvDRTj5MkmsHzKw0upvYyqiySRLYEHg0IpYCRMSjwNaSLu25QNJbJV0iaYSk6ak0t0DSpyVNAiYA56eS3mqSdpF0raRbJF0hacN0n1mSvi9prqQ7Je0q6VeS7pH09SZing28XtI6ki5NJeAbJe2QnrNA0trKPCbpg+n4uemzjJD0XUlz0ns/ks5PlDRb0gzgjtZ/tWZm7RFN/K+MqpwkrwRGS7pb0k8k7Q1cQ5Yo10/XHA2cDYwHNo6I7SNiHHBORPwSmAu8PyLGA8uAU4FJEbFLet83cs97KSImAKcDlwEfB7YHpkhat16wqYR3ILAA+CowL5WAvwCcmy67HngjsB2wGOhZynxP4AbgGOCpiNgV2BX4sKTN0zU7A5+MiC3r/+rMzAaHS5IFiYhngV2AqcAjwIXAUcB5wAckrU2WXH5HlnBeJ+lUSQcAT/dxy63Ikt5VkuYDXwQ2yZ2fkX4uABZGxEOpFLsYGN1PqKul+80F/g6cBeyV4iQi/gCsK2lNspLmm9N2GjBO0sbAExHxHLA/8MF0v5uAdYGx6Tk3R8S9fQUgaWoqBc8967I/9BOqmVl7dRENb2VU6fariOgCZgGzJC0gS5IfAX4NvAhcFBHLgCck7Qi8jaxN8L3Ah3rdTmTJb88aj1uafnbnXvfs9/d7fCGVVJc/SDVXIb2OrIS6KXAC8G5gElny7Inx2Ii4otf9JgLP1bppREwDpgG8eP355fyXaGZDUndU+09OZUuSkraSNDZ3aDzwt4h4EHiQrCR4Trp2PWCliLg4Hd85vecZYI30+i5g/dQhCEmrSNquQ+HPBt6fnjORrG316Yi4H1gPGBsRi4E/Ap8jS54AVwAfk7RKeu+WklbvUIxmZi2LJrYyqnJJchRwaqpWXQYsIqt6BTgfWD8i7kz7GwPnSOr5UvD59HM6cLqkF8iqZicBp0hai+x38wNgYQdiPxE4W9JtwPNkJeAeNwEj0uvZwLfIkiXAmcAY4FZlxdFHgHd1ID4zs7Yo69CORlU2SUbELcAbapzeCzgjd+2fWV56zN/jYuDi3KH5ZO2Bva+bmHs9i6yK9xXnasQ5qo9jj1MjuUXEkbnXN5Ar7UdEN1lHny/0etsKMZmZlUVZe602qrJJshZJt5C1z3226FjMzIa7svZabdSQS5Jp+MagSkNAru7j1L4R8dhgx2NmVhZdFU+TQy5JFiElwvFFx2FmVjbVTpFOkmZm1kFR8SEgTpJmZtYxVe/dWtlxkmZmVn7tnJZO0gGS7pK0SNLxfZx/laQL0/mbJI1pNX4nSTMz65guuhve+iNpBPBjsjmwtwUmS9q212XHkE3j+Xrg+8C3W43fSdLMzDomIhre6tgNWBQRiyPiJeAC4JBe1xwC/Cy9/iWwr/qZB7QRTpJmZtYxzVS35hdjSNvU3K02ZsU1g5ekY/R1TZq3+ymyhSAGzB13zMysY5qZcSe/GENZOEmamVnHtLF36wOsuCzhJulYX9csSWv4rgW0NKGLq1vNzKxj2tgmOQcYK2lzSSOBI1i+zm+PGSxfMGIS8IdocaCmS5JmZtYx7ZqWLiKWSfoE2ZKBI4CzI2KhpJOAuRExg2xR+/MkLQIeJ0ukLVHVZ0Ow5uw/+gD/H26vMIKWOgAW4qp/3lZ0CE154cHZ9S8qmVXWe13L/zDevPG+Df/Nue6Bq0v3D9ElSTMz65iqfyt3kjQzs46p+rR0TpJmZtYxTpJmZmY1dEW1F8tykjQzs45pZjKBMnKSNDOzjqn6CAonSTMz6xi3SZqZmdXgkqSZmVkNLkmamZnV4N6tZmZmNbh3q5mZWQ3dbpM0MzPrW9VLksNiPUlJJ0haKOk2SfMl7d7k+6dI2qhT8eWe8y5JIWnrTj/LzGwwdEc0vJXRkE+SkvYEDgJ2jogdgP2A+5u8zRSg40kSmAz8Mf00M6u8aOJ/ZTTkkySwIfBoRCwFiIhHga0lXdpzgaS3SrpE0ghJ0yXdLmmBpE9LmgRMAM5PpdDVJO0i6VpJt0i6QtKG6T6zJH1f0lxJd0raVdKvJN0j6ev9BSlpFLAXcAy5hUIlrSTpJ5L+IukqSZenmKgVh5lZWXRFd8NbGQ2HJHklMFrS3SnZ7A1cQ5Yo10/XHA2cDYwHNo6I7SNiHHBORPwSmAu8PyLGA8uAU4FJEbFLet83cs97KSImAKcDlwEfB7YHpkhat584DwFmRsTdwGOSdknHDwXGANsCRwJ7AkhapU4cZmaFi+hueCujId9xJyKeTQnnTcBbgAuB44HzgA9IOocs8XwQWAN4naRTgd+SJdjetiJLeldJAhgBPJQ7PyP9XAAsjIiHACQtBkYDj9UIdTLww/T6grR/C1np8qLI/gX9Q9I1DcbxMklTgakA26y9LZuMGl0jBDOz9vJkAhUQEV3ALGCWpAXAUcBHgF8DL5IloWXAE5J2BN4GfBR4L/ChXrcTWfLbs8bjlqaf3bnXPft9/r4lrQPsA4yTFGQJLyT9Zz8fq14cL4uIacA0gP1HH1Dtf7FmVilVn5ZuyFe3StpK0tjcofHA3yLiQeBB4IvAOena9YCVIuLidHzn9J5nyEqZAHcB66cOQUhaRdJ2LYY5CTgvIjaLiDERMRq4l6z0ez3wntQ2uQEwsYNxmJm1VTfR8FZGw6EkOQo4VdLaZO2Ji0hVj8D5wPoRcWfa3xg4R1LPl4fPp5/TgdMlvUBWNTsJOEXSWmS/wx8AC1uIcTLw7V7HLk7HPw7sC9xB1iv3VuCpiHgpdeBpZxxmZm3V1V3OtsZGqepF4VZI+hEwLyLOKjqW/kgaldpW1wVuBt4YEf8YyL1c3Wp9GYGKDqFpV/3ztqJDaMoLD84uOoSmrbLe61r+h/Hatbdp+G/OP568s3T/EIdDSbJPkm4BngM+W3QsDfhNKgmPBL420ARpZjbYql4QG7ZJMg2bGFSpJHh1H6f2jYhavV6JiIkdC8rMrIPK2tbYqGGbJIuQEuH4ouMwMxssLkmamZnVUNY5WRs15IeAmJlZcQZrWjpJ66SpO+9JP1/TxzXjJf0pt+DF4fXu6yRpZmYdExENby06Hrg6IsaS9f04vo9rngc+GBHbAQcAP0idImtykjQzs44ZxKWyDgF+ll7/DHhX7wsi4u6IuCe9fhB4GFi/93V5TpJmZtYxzSyVJWlqWkWpZ5ta/wkv26BnrmzgH8AG/V0saTeyYXV/7e86d9wxM7OOaaaEmJ9nui+Sfg+8to9TJ/S6T6R5sGvdZ0OyRS6OijrLjzhJmplZx7RzCEhE7FfrnKR/StowIh5KSfDhGtetSbbK0wkRcWO9Z7q61czMOqY7uhveWjSDbIUn0s/Lel8gaSRwCXBuWiu4LidJMzPrmEHs3Xoy8FZJ9wD7pX0kTZB0ZrrmvcCbgSmS5qdtfH83dXWrmZl1zGBNJZBmNNu3j+NzgX9Pr38O/LyZ+w7rVUCsfSRNTY3uleGYO69q8YJjthW5utXapZmu2mXhmDuvavGCY7YcJ0kzM7ManCTNzMxqcJK0dqlie4hj7ryqxQuO2XLcccfMzKwGlyTNzMxqcJI0MzOrwUnSzMysBidJMzOzGjwtnQ2YpC2B08jWcdte0g7AwRHx9YJD65ekzYCxEfF7SasBK0fEM0XH1R9JGwObkftvNiKuKy6i2iS9CngPMIYV4z2pqJj6I2kEsDAiti46lmZI2gD4JrBRRBwoaVtgz4g4q+DQhhSXJK0VZwCfB/4FEBG3AUcUGlEdkj4M/BL4aTq0CXBpYQE1QNK3geuBLwL/mbbPFRpU/y4jWyV+GfBcbiuliOgC7pK0adGxNGk6cAWwUdq/G/hUUcEMVS5JWiteHRE3S8ofW1ZUMA36OLAbcBNARNwj6d+KDamudwFbRcTSogNp0CYRcUDRQTTpNcBCSTeTS+gRcXBxIdW1XkT8QtLnASJimaSuooMaapwkrRWPStqCNNG/pEnAQ8WGVNfSiHipJ7FLWpnBW6hgoBYDqwBVSZI3SBoXEQuKDqQJXyo6gAF4TtK6LP/vbw/gqWJDGnqcJK0VHyeb6WNrSQ8A9wIfKDakuq6V9AVgNUlvBf4D+HXBMfVJ0qlkfwCfB+ZLuppcooyI44qKrY69yNbru5csXgERETsUG1ZtEXFtr7bqVwMjio6rjs+QLTS8haTrgfWBScWGNPR4xh1rmaTVgZXK3vkFQFkR8t+B/cn+eF8BnBkl/A9B0lH9nI6IOHfQgmlCSjavEBF/G+xYGpXaqqcC60TEFpLGAqdHxCvWJyyTVBOyFdm/5bsi4l8FhzTkOEnagEn6JvCdiHgy7b8G+GxEfLHQwGqocC/GT0bED+sdKxNJOwJvSruzI+LPRcZTj6T5pLbqiNgpHVsQEeMKDawfkg7t4/BTwIKIeHiw4xmq3LvVWnFgT4IEiIgngLcXF07/KtyLsa8S5ZTBDqJRkj4JnA/8W9p+LunYYqOqa2lEvNSzU5G26mOAM4H3p+0M4L+B6yUdWWRgQ4nbJK0VIyS9qqfXZRpz+KqCY6qnMr0YJU0G3gdsLmlG7tQawOPFRNWQY4DdI+I5eHkIy5+AUwuNqn+VaavOWRnYJiL+CS+PmzwX2B24DjivwNiGDCdJa8X5wNWSzkn7RwM/KzCeRlSpF+MNZL2F1wP+J3f8GeC2QiJqjID8UISudKzMjidL7guAjwCXk5XSymx0T4JMHk7HHpfktsk2cZuktUTSgUBP54arIuKKIuOx4kn6DFkV8SXp0LuA6RHxg6JiqkfSvsANEfFC0bE0StJPgE2Bi9KhScASsokmfhMRbykqtqHESdKGFUnPsLytaSTZ+MPnImLN4qLqX0Vj3plsKAhkHXfmFRlPPZJ+BuxJVo09m6y68o+pnb2UUk/tQ1n+e74+In5ZYEhDkpOkDVjqXfdtss4ZYvl4uNL+8c5Lf2QOAfaIiOOLjqcRZY5Z0poR8bSkdfo6HxFlbkcFQNJGZCWyz5HNiVqZJilJbwKOiIiPFx3LUOIkaQMmaRHwzoi4s+hYWiFpXk+3/6ooY8ySfhMRB6VJBPJ/WHq+PL2uoNDqkvQBsiEr44BHgT+SlYD/VGhgdUjaCZgMvJdsMo9fRUSZO0hVTmW+JVkp/bNqCbLX2LKVgAnAiwWF05CqxBwRB6WfmxcdywD8APgrcDpwTUTcV2g0/Uir70xO26PAhWQFHrdBdoBLkjZgkn4IvJZsFY38dGm/KiqmenI9cSGbjP0+4IwyD76uWsySru49U01fx8pG0nbAm8na+MaSzWBTuvGGkrrJ2k2PiYhF6djiMpfUq8wlSWvFmmTziu6fOxZAaZMk2RR01+cPSHojWff5UoqIo4uOoRGSVgVeDayXZl/qGfaxJrBxYYE1QNKaZD1FNyNbB3MtoLvImPpxKNmSdNdImglcQPmH2FSWS5I2rEi6NSJ2rnesTCRtDhzLKxcxLtUECGmmnU+RrW/4AMv/cD9NVvL9UUGh1SXpNrJ2yD8C10XEkoJDqivNmXwIWbXrPmQTCVwSEVcWGtgQ4yRpA5ZKDscA2wGr9hyPiA8VFlQNkvYE3kD2R/z7uVNrAu+OiB2LiKsRkv4MnEU20P3l0k1EXFtYUP2QdGxVO49IGgUQEc8WHUszUsn9MODwnmptSa8p8xCWqnB1q7XiPOAvwNuAk8jmjyxrR56RwCiyf/Nr5I4/TfmXF3oxIk4pOohGRcSpkrYHtmXFL0+lXLUEIMV7HrBOtqtHgKMi4vZiI2tMSobT0tbjaqC0NSRV4ZKkDVjPMARJt0XEDpJWIes2v0fRsdUiabMyL9nUF0nvI+tIciUrdpC6tbCg+iHpK8BEsiR5OXAg2cD80n4ZkXQDcEJEXJP2JwLfjIg3FBlXK8o4TKiKXJK0VvTMD/lk+ib+D7KJBcrseUnf5ZVVxPsUF1Jd44AjydqdeqpbI+2X0SRgR2BeRBydJt7+ecEx1bN6T4IEiIhZqc2vylwCagMnSWvFtNQW8iWyFdJHAV8uNqS6zicbV3YQ8FGyOUYfKTSi+g4DXpdfyqnkXoiIbknLUq/Rh4HRRQdVx2JJX2L5yhkfABYXGI+VhJOkDVhE9KyScC1QlTFa60bEWWnR4mvJlkiaU3RQddwOrE2Jh6n0MlfS2mTrG94CPEu2VFaZfQj4KtnwpSAbh1i6DmhN8rCQNnCStKZJ+kBE/Dyt9vAKEfG9wY6pCT1VxA9JegfwIFlnjTJbG/hLSub5NslSDQHpERH/kV6ensbxrRkRpVzaK/XQ/ijwerLew5+NiMosM5Vqckaz4tCgnrbqUk/eUBVOkjYQPW01a/R7VTl9XdJawGfJFgFeE/h0sSHV9ZWiA2hGWiD6AuCyMk/vlvyM7IvTbLIORtuQDRMqPUlfA6aQTafX0/74clt1FSaUrwL3brVhQ9II4LiI+H7di23AJO0NHA68A5hDljB/ExGlm29W0oKIGJderwzcXOaJJfIk3QWMq1BbdSW5JGlNk9TvmL2IOG6wYmlGRHRJmsyKkwmUlqQ/RsRevdaThJIvSZZr6x1BVqr5MHA2Wam9bF6uWo2IZdlKZJVRtbbqSnKStIG4Jf18I9lYuAvT/mHAHYVE1LjrJf2ILObneg6WccxhROyVflauWlvSasA7yUqUO5NVa5bRjpKeTq8FrJb2S/1FJPkWME/S7VSgrbqqXN1qAybpRmCviFiW9qswmcA1fRyOMo+TlHQWcGpEzM8dOzEiTiwsqH5I+gWwGzCT7MvItRFR1snCG1LGKd4kLQR+SkWmK6wqJ0kbsNQmsmdPB4HU0+7GiNiq2MiGFklLgMeA70XEz9Kx0k7KLultwO8joqvoWNqljL9vSXMiYtei4xjqVio6AKu0k8mqe6ZL+hlwK/DNgmPql6QNJJ0l6Xdpf1tJxxQdVx0Pk61zOEnSj1MHkzI3ns0GPi9pGoCksZIOKjimVpXx9z1b0rck7Slp556t6KCGGpckrSWSXgvsnnZvioh/FBlPPSk5nkM2T+eOKeHM6+nhWEb5OTglnQjsB2xU1kV2JV1I1m79wYjYXtKrgRsiYnyxkQ1cSUuSlWs6qCJ33LFWLQUeIpsHdUtJW0bEdQXH1J/1IuIXkj4PL/doLHu14IyeFxFxoqRbKPdYvi0i4vDUk5iIeF4V6zZaBRHxlqJjGA5c3WoDJunfgeuAK8im9LoCOLHImBrwnKR1SUMqJO0BPFVsSP2LiN6TCTxBtkRZWb2Uerf2/I63INf7sqJKl+Qr2nRQOU6S1opPArsCf0vfancCniw0ovo+Q1Yy20LS9WSruR9bbEj1SdpJ0ncl3Qd8jfKu2wnZDEEzgdGSzidb1/C/ig2pPkmvkbRDjfa9Mk7xNp3si+lGaf9uyl3DUEmubrVWvBgRL0pC0qsi4i+SSt2zNSJuTTPCbEVWOrirrHN1StoSmJy2R8mGU6js1WwRcZWkW4E9yH7Hn4yIRwsOq18VneKtik0HleMkaa1YklZ7uBS4StITQKkXNE4TWv8HsBdptQdJp5dxyjSyKtXZwEERsQhAUmnnme2jZ+VD6eemkjYt44QNOe8la0ut0hRvlWs6qCL3brW2SKWztYCZZf5Dkwa6P8PyRYDfB6wdEYcVF1XfJL0LOIJsZqOZZHOgnhkRmxcZVy01elv2KHWvS0kXAx+LiMpM8Za+lJwKbE82Rd36wGER8edCAxtinCRtQNK8nAsjYuuiY2mGpDsiYtt6x8pE0urAIWTVrvuQtaNeEhFXFhrYECJpAnAZWbKpxBRvkl4FdJFrOgBWioiqd5IqFXfcsQFJs6ncJWnTomNp0q2pWgoASbsDcwuMp66IeC4i/jci3glsAswD/rvnfJrpqHCS/iv3+rBe50o9yQTZ3LLfJpsg439yW5n9KSKWRcTCiLg9ta2XfXHrynFJ0gZM0nVkPVpvZsXJwsv87ftOsm/ef0+HNiX7Br6MrEpwh6JiG6iyDHTPx9E7prLEWEuVpnhLE3hsTNZk8D6WD09ZEzi9arU7ZeeOO9aKLxUdwAAcUHQAHVCWMXyq8bqv/bKZLelbZMOD8tWtZexs9DaynribkJV2e363zwBfKCimIctJ0gYktUn+tGrfWiPib6l6cjS5f/8l/WPYqLJUB0WN133tl81O6Wd+BZuXh4CUSZrk/meS3hMRFxcdz1DnJGkDkhYwvit17f97/XeUQ73xcNaSnrUZ8+sykvZXLS6s+so+9rSGTSStSVaCPINs3c7j3aGrvZwkrRWvARZKqkybJNUcD1dPKaoyI2JEI9eVdG3GDchWsNkoIg6UtC3ZMnBnFRxafz4UET9MS5OtCxwJnAc4SbaRk6S1ooptkrcDa5MtP1UZqXp7A1asIu4pwZdxyrT+XE1W6imT6aTVYdL+3WQzHJU5SfZ8OXo7cG5ELPRE8u3nJGkDVtEV0L9FtgZmlcbDHUs2H+o/Wb4CfQA7QGmnTOtPGf+QV3GKt1skXQlsTrZ+5xos//dhbeIkaU2T9Ax9d8QQ2TCKNQc5pGb0jIdbQHX+oHwS2CoiHis6kDYpYyeeKk7xdgwwHlicliNbFzi62JCGHidJa1pErFF0DC14PiJOKTqIJt1P+f9gV13v1WHWB0o3VWEvFwFnA/MB0peoofJFqjQ8mYANK5K+R1bNWoXxcABIOotsAoTfsmLM3yssqBZImhcRO9W/cvBUcYo3SfuRlRz3IEuY50TEXcVGNfS4JGnDTWXGw+X8PW0j01Z6Fexo9Kc0I9DCngNpua+ydTB6WUT8Hvi9pLXI5vX9vaT7yYaD/LysS8BVjUuSZtZWtToalXHKv6pP8ZbaIT9ANvzjQeB8smXgxkXExAJDGzKcJG1YqeJ4uLQE1Sv+Qy3r0lOSFgG7V6GjkaSjyCaXmADMYcUp3qZHxK8KCq0uSZeQVQ+fR1bV+o/cubkRMaGw4IYQJ0kbViT9jjQeLiJ2lLQyMC8ixhUcWk2Sdsntrgq8B1gWEf9V4y2FSkn9rRGxrOhYGlWlKd4k7UrWmWubiLgmJfpDyRY8P7GCQ4JKzW2SNtxUbjxcRNzS69D1aZajsloMzJJUpY5GVZri7afAfilBvpls7O+xZMNBpgGTCoxtyHGStGFB0sqpZFO58XCS1sntrkRWNbhWQeE0onIdjajWFG8jcqXFw4FpqRR8saT5xYU1NDlJ2nBxM1np4LO8cjxc2b9538LyNsllwH1kA8lLKSK+WnQMA1ClKd5G5L707QtMzZ3z3/Q28y/UhgtBVnUpaW9y4+HK2lW+p+0pIjZP+0eRtUfeB9xRYGj9qlpHo6RKU7z9H3CtpEeBF4DZAJJeT8lrRarIHXdsWJC0BKjZJlbG9rI0Tm+/iHg8tT1dwPK2p20iopQl4Kp1NAKQtBLLp3h7MlXJbxwRtxUbWd9SM8GGwJUR8Vw6tiUwqswTY1SRS5I2XIwARlHOybVrqWTbUwU7GkHFpniLiBv7OHZ3EbEMdU6SNlw8FBEnFR1EkyrZ9lTBjkYAp5FN8XaKJE/xZi8r7X9oZm3WUAmyZAsCV7XtqVIdjcBTvFltbpO0YUHSOo0MspZ0a5rDsxSq1PaU62j0j7Sf72hU+kHunuLN+uIkaZZTxhUqqqKqHY3AU7xZbSsVHYBZyfhb48D12dEoIr4EvL7AuGqStGua5PyUiNiWrAT5U0mn9LStOkEOb06SZtYuI9JcuJB1NPpD7lxZ+z/8FHip1xRv55K1+U4rNDIrhbL+wzUrSpWGiJRNFTsaVXKYjQ0elyRtWJF0Xp1jZVwQuBIi4htk0/5NB/aK5R0eViJrmyyjKpZ+bRD5H4ENN9vldySNAF6eIabsPTDLroKD3KtY+rVB5N6tNiykpbG+AKwGPN9zGHiJrIrt80XFZsWq0jAbG3xOkjasSPqWE6KZNcpJ0oYdSRsDm5FrboiI64qLyMzKym2SNqxIOhk4gmypqa50OAAnSTN7BZckbViRdBewQ0QsLToWMys/DwGx4WYxsErRQZhZNbi61Yab54H5kq4GXi5NRsRxxYVkZmXlJGnDzYy0mZnV5TZJG3YkrQZs6kV1zawet0nasCLpncB8YGbaHy/JJUsz65OTpA03JwK7AU8CRMR84HXFhWNmZeYkacPNvyKi95yc3YVEYmal5447NtwslPQ+stUfxgLHATcUHJOZlZRLkjbcHEu2EshSshUgngY+VWRAZlZe7t1qZmZWg6tbbViQ9IOI+JSkX5PN1bqCiDi4gLDMrOScJG24OC/9/H+FRmFmleLqVht2JI0EtiYrUd4VES8VHJKZlZSTpA0rkt4BnA78FRCwOfCRiPhdoYGZWSk5SdqwIukvwEERsSjtbwH8NiK2LjYyMysjDwGx4eaZngSZLAaeKSoYMys3d9yxYUHSoenlXEmXA78ga5M8DJhTWGBmVmpOkjZcvDP3+p/A3un1I8Bqgx+OmVWB2yTNzMxqcEnShhVJm5NNTTeG3L9/TyZgZn1xkrTh5lLgLODXePUPM6vD1a02rEi6KSJ2LzoOM6sGJ0kbVtIyWWOBK8lWAgEgIm4tLCgzKy1Xt9pwMw44EtiH5dWtkfbNzFbgkqQNK5IWAdt6vlYza4Rn3LHh5nZg7aKDMLNqcHWrDTdrA3+RNIflbZIREYcUF5KZlZWrW21YkbR3fhd4E3BERGxXUEhmVmKubrVhJSKuBZ4GDgKmk3XYOb3ImMysvFzdasOCpC2ByWl7FLiQrCblLYUGZmal5upWGxYkdQOzgWNya0kujojXFRuZmZWZq1ttuDgUeAi4RtIZkvYla5M0M6vJJUkbViStDhxCVu26D3AucElEXFloYGZWSk6SNmxJeg3ZosuHR8S+RcdjZuXjJGlmZlaD2yTNzMxqcJI0MzOrwUnSzMysBidJMzOzGv4/WZw+7w+hx20AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix\n",
    "corr_matrix = X_training.corr()\n",
    "sn.heatmap(corr_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ebf5f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling of the features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_training)\n",
    "X_training_scaled = scaler.transform(X_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4227e",
   "metadata": {},
   "source": [
    "# Multi Classification Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1bfbd894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6215686274509804\n",
      "Accuracy pol: 0.7503267973856209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train_mc, y_val_mc = train_test_split(X_training_scaled, y_mc_train1d, test_size=0.15, random_state=4720)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pol = PolynomialFeatures(degree=3)\n",
    "pol.fit(X_train)\n",
    "X_train_pol = pol.transform(X_train)\n",
    "X_val_pol = pol.transform(X_val)\n",
    "lr = LogisticRegression(multi_class='multinomial',max_iter=1000)\n",
    "y_pred = lr.fit(X_train, y_train_mc).predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val_mc, y_pred))\n",
    "lr_pol = LogisticRegression(multi_class='multinomial',max_iter=1000)\n",
    "y_pred_pol = lr_pol.fit(X_train_pol, y_train_mc).predict(X_val_pol)\n",
    "print(\"Accuracy pol:\", accuracy_score(y_val_mc, y_pred_pol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d05c5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.711764705882353\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=90)\n",
    "y_pred = rfc.fit(X_train, y_train_mc).predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val_mc, y_pred))   #meglio linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be14bf1",
   "metadata": {},
   "source": [
    "don't run it's heavy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "19cc11db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=svm.SVC(kernel='rbf',C=700, coef0=0.0, tol=1e-3),n_estimators=10, random_state=0)\n",
    "y_pred = bag.fit(X_train, y_train_mc).predict(X_val)\n",
    "print(\"Accuracy:\", accuracy_score(y_val_mc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b5352f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svmgauss = svm.SVC(kernel='rbf',C=700).fit(X_train, y_train_mc)\n",
    "y_prediction_svmguass = clf_svmgauss.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64585ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with linear features: 0.7797385620915033\n"
     ]
    }
   ],
   "source": [
    "Accuracy_svmG = accuracy_score(y_val_mc,y_prediction_svmguass)\n",
    "print(\"Accuracy with linear features: \" + str(Accuracy_svmG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5196f1",
   "metadata": {},
   "source": [
    "# Multi Classification Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f331281a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with polynomial features: 0.7888888888888889\n",
      "Accuracy with linear features: 0.696078431372549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "FF_NN = MLPClassifier(hidden_layer_sizes=(X_train_pol.shape[1], 3), activation='relu', solver='adam', max_iter=200, shuffle=True, random_state=1, tol=0.0001, verbose=False, early_stopping=False, validation_fraction=0.1)\n",
    "y_pred = FF_NN.fit(X_train_pol, y_train_mc).predict(X_val_pol)\n",
    "print(\"Accuracy with polynomial features:\", accuracy_score(y_val_mc, y_pred))\n",
    "\n",
    "FF_NN = MLPClassifier(hidden_layer_sizes=(X_train.shape[1], 5), activation='relu', solver='adam', max_iter=200, shuffle=True, random_state=1, tol=0.0001, verbose=False, early_stopping=False, validation_fraction=0.1)\n",
    "y_pred = FF_NN.fit(X_train, y_train_mc).predict(X_val)\n",
    "print(\"Accuracy with linear features:\", accuracy_score(y_val_mc, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d913652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53a557d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "\n",
    "def baseline_model(layers,nodes):\n",
    "\t# create model 1 hidden layer with 8 nodes\n",
    "    #nodes=8\n",
    "    input_node=6\n",
    "    output_node=4\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes[0], input_dim=input_node, activation='relu'))\n",
    "    for i in range(1,layers):\n",
    "        model.add(Dense(nodes[i], activation='relu'))\n",
    "    model.add(Dense(output_node, activation='softmax'))    #activation='softmax' for muticlass\n",
    "\t# Compile mode\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30af546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=4\n",
    "nodes=[6,6,5,4]\n",
    "model=baseline_model(layers,nodes)\n",
    "#visualize_nn(model, description=True, figsize=(10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6f52c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# work with labels\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_val_mc)\n",
    "encoded_Y = encoder.transform(y_val_mc)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_val = np_utils.to_categorical(encoded_Y)\n",
    "print(dummy_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10af7d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# work with labels\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_mc)\n",
    "encoded_Y = encoder.transform(y_train_mc)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_Y)\n",
    "print(dummy_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "def73273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4728 - accuracy: 0.7962\n",
      "Epoch 2/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4703 - accuracy: 0.7990\n",
      "Epoch 3/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4746 - accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4750 - accuracy: 0.7963\n",
      "Epoch 5/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4775 - accuracy: 0.7937\n",
      "Epoch 6/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4732 - accuracy: 0.7979\n",
      "Epoch 7/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4705 - accuracy: 0.7993\n",
      "Epoch 8/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4768 - accuracy: 0.7961\n",
      "Epoch 9/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4770 - accuracy: 0.7984\n",
      "Epoch 10/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4692 - accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4716 - accuracy: 0.7983\n",
      "Epoch 12/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4742 - accuracy: 0.7998\n",
      "Epoch 13/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4729 - accuracy: 0.7980\n",
      "Epoch 14/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4695 - accuracy: 0.7982\n",
      "Epoch 15/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4718 - accuracy: 0.7963\n",
      "Epoch 16/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4718 - accuracy: 0.7961\n",
      "Epoch 17/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4748 - accuracy: 0.8002\n",
      "Epoch 18/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4700 - accuracy: 0.7984\n",
      "Epoch 19/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4677 - accuracy: 0.7973\n",
      "Epoch 20/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.8006\n",
      "Epoch 21/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4732 - accuracy: 0.7960\n",
      "Epoch 22/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4685 - accuracy: 0.7998\n",
      "Epoch 23/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.7992\n",
      "Epoch 24/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4717 - accuracy: 0.7986\n",
      "Epoch 25/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4685 - accuracy: 0.7990\n",
      "Epoch 26/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4736 - accuracy: 0.7961\n",
      "Epoch 27/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4712 - accuracy: 0.7993\n",
      "Epoch 28/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4869 - accuracy: 0.7912\n",
      "Epoch 29/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4718 - accuracy: 0.7967\n",
      "Epoch 30/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.8009\n",
      "Epoch 31/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4672 - accuracy: 0.8007\n",
      "Epoch 32/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4661 - accuracy: 0.7988\n",
      "Epoch 33/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4697 - accuracy: 0.7993\n",
      "Epoch 34/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4703 - accuracy: 0.8003\n",
      "Epoch 35/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4708 - accuracy: 0.7969\n",
      "Epoch 36/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4787 - accuracy: 0.7955\n",
      "Epoch 37/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4688 - accuracy: 0.7988\n",
      "Epoch 38/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4662 - accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.7986\n",
      "Epoch 40/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4762 - accuracy: 0.7977\n",
      "Epoch 41/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4676 - accuracy: 0.8012\n",
      "Epoch 42/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4693 - accuracy: 0.7963\n",
      "Epoch 43/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.8006\n",
      "Epoch 44/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4711 - accuracy: 0.7953\n",
      "Epoch 45/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4737 - accuracy: 0.7958\n",
      "Epoch 46/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4732 - accuracy: 0.7963\n",
      "Epoch 47/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4717 - accuracy: 0.7993\n",
      "Epoch 48/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4664 - accuracy: 0.8009\n",
      "Epoch 49/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4704 - accuracy: 0.7999\n",
      "Epoch 50/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4655 - accuracy: 0.7984\n",
      "Epoch 51/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4700 - accuracy: 0.7997\n",
      "Epoch 52/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.7982\n",
      "Epoch 53/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4669 - accuracy: 0.8023\n",
      "Epoch 54/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4685 - accuracy: 0.7968\n",
      "Epoch 55/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4758 - accuracy: 0.7990\n",
      "Epoch 56/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4687 - accuracy: 0.7968\n",
      "Epoch 57/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4724 - accuracy: 0.7976\n",
      "Epoch 58/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4705 - accuracy: 0.7998\n",
      "Epoch 59/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4708 - accuracy: 0.7938\n",
      "Epoch 60/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4658 - accuracy: 0.7995\n",
      "Epoch 61/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.8016\n",
      "Epoch 62/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4744 - accuracy: 0.7975\n",
      "Epoch 63/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4713 - accuracy: 0.7987\n",
      "Epoch 64/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4717 - accuracy: 0.8001\n",
      "Epoch 65/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4729 - accuracy: 0.7968\n",
      "Epoch 66/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4738 - accuracy: 0.7973\n",
      "Epoch 67/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4659 - accuracy: 0.8018\n",
      "Epoch 68/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4724 - accuracy: 0.7980\n",
      "Epoch 69/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4702 - accuracy: 0.8018\n",
      "Epoch 70/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4831 - accuracy: 0.7941\n",
      "Epoch 71/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4708 - accuracy: 0.7995\n",
      "Epoch 72/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4720 - accuracy: 0.7942\n",
      "Epoch 73/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4645 - accuracy: 0.7997\n",
      "Epoch 74/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4729 - accuracy: 0.7953\n",
      "Epoch 75/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4682 - accuracy: 0.8002\n",
      "Epoch 76/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4683 - accuracy: 0.7950\n",
      "Epoch 77/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4700 - accuracy: 0.7982\n",
      "Epoch 78/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4697 - accuracy: 0.7979\n",
      "Epoch 79/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4659 - accuracy: 0.7993\n",
      "Epoch 80/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4726 - accuracy: 0.8005\n",
      "Epoch 81/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4708 - accuracy: 0.7984\n",
      "Epoch 82/100\n",
      "867/867 [==============================] - 4s 4ms/step - loss: 0.4705 - accuracy: 0.7999\n",
      "Epoch 83/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4706 - accuracy: 0.7988\n",
      "Epoch 84/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4692 - accuracy: 0.7997\n",
      "Epoch 85/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4683 - accuracy: 0.8012\n",
      "Epoch 86/100\n",
      "867/867 [==============================] - 3s 4ms/step - loss: 0.4675 - accuracy: 0.7990\n",
      "Epoch 87/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4683 - accuracy: 0.7984\n",
      "Epoch 88/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4701 - accuracy: 0.7973\n",
      "Epoch 89/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4705 - accuracy: 0.7987\n",
      "Epoch 90/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4666 - accuracy: 0.7997\n",
      "Epoch 91/100\n",
      "867/867 [==============================] - 4s 5ms/step - loss: 0.4716 - accuracy: 0.8006\n",
      "Epoch 92/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4705 - accuracy: 0.7973\n",
      "Epoch 93/100\n",
      "867/867 [==============================] - 2s 2ms/step - loss: 0.4695 - accuracy: 0.7961\n",
      "Epoch 94/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4670 - accuracy: 0.7991\n",
      "Epoch 95/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4662 - accuracy: 0.8012\n",
      "Epoch 96/100\n",
      "867/867 [==============================] - 3s 3ms/step - loss: 0.4672 - accuracy: 0.7978\n",
      "Epoch 97/100\n",
      "867/867 [==============================] - 2s 3ms/step - loss: 0.4673 - accuracy: 0.7986\n",
      "Epoch 98/100\n",
      "867/867 [==============================] - 2s 2ms/step - loss: 0.4741 - accuracy: 0.7953\n",
      "Epoch 99/100\n",
      "867/867 [==============================] - 2s 2ms/step - loss: 0.4672 - accuracy: 0.8010\n",
      "Epoch 100/100\n",
      "867/867 [==============================] - 2s 2ms/step - loss: 0.4662 - accuracy: 0.8007\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, dummy_y_train, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "39be0550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 3 ... 0 3 0]\n",
      "Accuracy: 78.17\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_val)\n",
    "print(pred.argmax(axis=1))\n",
    "accuracy = accuracy_score(dummy_y_val.argmax(axis=1),pred.argmax(axis=1))\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9f28b9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7817\n",
      "Accuracy: 78.17\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_,accuracy = model.evaluate(X_val, dummy_y_val)   \n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "67785a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[678,  63,  23,   4],\n",
       "       [ 77, 165,   1,   7],\n",
       "       [ 93,  34, 113,  14],\n",
       "       [  1,   5,  12, 240]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mc_predict=model.predict(X_val,batch_size=10)\n",
    "matrix = confusion_matrix(dummy_y_val.argmax(axis=1), y_mc_predict.argmax(axis=1))\n",
    "matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
